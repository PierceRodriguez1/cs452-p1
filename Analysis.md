My multi-threaded sorting program produced a graph that was similar to the expected examples, showcasing an initial decrease in sorting time with the increasing number of threads up to an optimal point, followed by a slowdown. This pattern aligns with the examples from Shaneâ€™s M1 Mac and the Intel server, indicating that my implementation generally performed as expected. The slowdown beyond the optimal number of threads was due to increased overhead from thread management and context-switching, which outweighed the benefits of parallel execution. On my machine, the best performance occurred with 8 to 10 threads, reflecting the maximum number of cores that could be utilized efficiently.

While my graph mirrored the overall trend seen in the example graphs, slight deviations were present due to differences in hardware capabilities such as core count, cache size, and thread scheduling policies. The slowest performance was observed with more than 20 threads, where overhead significantly impacted execution time. Upon reviewing my code, I confirmed that there were no critical implementation issues, although any potential flaws, such as inefficient task splitting or synchronization problems, could have affected performance. Overall, my results followed the expected behavior of multi-threaded sorting, balancing improved speed with thread management limits.